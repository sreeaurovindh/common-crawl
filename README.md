Deducing Structure of the Web
=============================

The goal of the project is to classify the structure of web pages and aggregate these structures based on frequency and domain information. This project would enable focused crawling of webpages and would help researchers to extract data at a web scale.  Due to enormity and unstructuredness of the dataset, we have planned to use tools from the Hadoop eco-system (Apache Pig with Tez, Apache Hive and HBase).

Dataset 
-------

The dataset used for this project is from the May 2015 crawl of the web (Common Crawl) , which consists of over 159 TB of data with more than 2.05 billion webpages.

Idea credits : http://research.microsoft.com/en-us/projects/website_structure_mining/ 

Data Credits : http://commoncrawl.org/ 
 
